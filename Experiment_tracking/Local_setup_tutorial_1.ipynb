{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8a48ab",
   "metadata": {},
   "source": [
    "MLflow is a tool to manage end-to-end machine learning pipelines. It helps you track and record various machine learning experiments. It has 4 major components. \n",
    "\n",
    "\n",
    "1. MLflow Tracking\n",
    "2. MLflow Projects\n",
    "3. MLflow Models\n",
    "4. MLflow Model Registry\n",
    "\n",
    "I have written about each of them in the blog. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ba767",
   "metadata": {},
   "source": [
    "MLflow concepts:\n",
    "\n",
    "MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code. Each run records the following information:\n",
    "\n",
    "1. Code Version : Git commit hash used for the run, if it was run from an MLflow Project.\n",
    "\n",
    "2. Start & End Time :Start and end time of the run\n",
    "\n",
    "3. Parameters :Key-value input parameters of your choice. Both keys and values are strings.\n",
    "\n",
    "4. Metrics : Key-value metrics, where the value is numeric. Each metric can be updated throughout the course of the run (for example, to track how your model’s loss function is converging), and MLflow records and lets you visualize the metric’s full history.\n",
    "\n",
    "5. Artifacts : Output files such as model and others. \n",
    "\n",
    "\n",
    "MLflow runs can be recorded to\n",
    "1. local files\n",
    "2. to a SQLAlchemy compatible database, \n",
    "3. remotely to a tracking server.\n",
    "By default, the MLflow Python API logs runs locally to files in an mlruns directory wherever you ran your program. You can then run mlflow ui to see the logged runs.\n",
    "\n",
    "MLflow uses two components for storage: backend store and artifact store.\n",
    "While the **backend store** records runs, model's parameters, metrics, tags, notes, metadata, etc), the **artifact store** records artifacts like (files, models, images, in-memory objects, or model summary, etc).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301c092",
   "metadata": {},
   "source": [
    "### MLflow setup:\n",
    "\n",
    "Tracking server: no\n",
    "\n",
    "Backend store: local filesystem\n",
    "\n",
    "Artifacts store: local filesystem\n",
    "\n",
    "\n",
    "For this example both backend store and artifact store will be done locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e00416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76a0334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660b8d3",
   "metadata": {},
   "source": [
    "Till now, we don't have mlruns directory. It will be created after executing next cell in the present directory only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca90587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()\n",
    "## This will create the mlflow directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a330189e",
   "metadata": {},
   "source": [
    "**Creating an example and using new run**\n",
    "\n",
    "MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code. Each run records the following information:\n",
    "\n",
    "\n",
    "1. Code Version\n",
    "2. Git commit hash used for the run, if it was run from an MLflow Project.\n",
    "3. Start & End Time\n",
    "4. Parameters\n",
    "5. Key-value input parameters of your choice. Both keys and values are strings.\n",
    "6. Metrics\n",
    "7. Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9f0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6e08cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/17 15:14:48 INFO mlflow.tracking.fluent: Experiment with name 'experiment-local-run' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1', experiment_id='1', lifecycle_stage='active', name='experiment-local-run', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"experiment-local-run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44b5c5",
   "metadata": {},
   "source": [
    "We can log models in two ways. One using **mlflow.log_model** and one using **mlflow.log_artifacts**. We will see second flavor in a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1c1f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1/819b61d672f84cdfa675f6c0ce0a16a9/artifacts'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/envs/mlflow_env/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    mlflow.set_tag(key = \"Message\",value=\"This uses mlflow.log_model flavor to log the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ed2ea",
   "metadata": {},
   "source": [
    "Now, you can use **mlflow ui** to see your experiment result.  Go to url \"http://localhost:5000/#/experiments/1\" to see your experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fe521",
   "metadata": {},
   "source": [
    "Till now for \"experiment-local-run\" we have one run and correpondingly one folder indise mlfruns/1/ folder. Let's now change 'C' to 0.5 and then see.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e81d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1/5265c129630040a9b2ef8657d48eb84e/artifacts'\n"
     ]
    }
   ],
   "source": [
    "## let's now change c to 0.5 and then record the experiment\n",
    "mlflow.set_experiment(\"experiment-local-run\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.5, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    mlflow.set_tag(key = \"Message\",value=\"This uses mlflow.log_model flavor to log the model but with a different c value\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d994285",
   "metadata": {},
   "source": [
    "Go inside mlruns folder. Folder with name mlruns\\1\\ denote experiment. This has now two folder correspoinding to each run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a9b84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1', experiment_id='1', lifecycle_stage='active', name='my-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f084b5d",
   "metadata": {},
   "source": [
    "### Creating an another experiment from here onwards\n",
    "\n",
    "Here, we will change model saving. It will use mlflow.log_artifact flavor of saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6abb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4feae25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/17 15:48:50 INFO mlflow.tracking.fluent: Experiment with name 'experiment-local-run-diff-flavor-model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/2/4cf3a14847cf47a0b2cca7c79aa184f5/artifacts'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/envs/mlflow_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"experiment-local-run-diff-flavor-model\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.8, \"random_state\": 56}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "    with open(\"Local_model_folder/logistic_regression.pkl\",'wb') as f:\n",
    "        pickle.dump(lr,f)\n",
    "    mlflow.log_artifact(\"Local_model_folder/logistic_regression.pkl\", artifact_path=\"models\")\n",
    "    \n",
    "\n",
    "#     mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "235ee864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1', experiment_id='1', lifecycle_stage='active', name='experiment-local-run', tags={}>,\n",
       " <Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>,\n",
       " <Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/2', experiment_id='2', lifecycle_stage='active', name='experiment-local-run-diff-flavor-model', tags={}>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34274f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atrifact uri is file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/2/3534052c37904b068e7101d485316ccb/artifacts\n"
     ]
    }
   ],
   "source": [
    "print (\"Atrifact uri is {}\".format(str(mlflow.get_artifact_uri())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac070d5",
   "metadata": {},
   "source": [
    "Bonus tip: If you will go and see \"UI\" you will find the differences in the model tab in \"experiment-local-run\" experient and model tab in \"experiment-local-run-diff-flavor-model\". Model saving using MLFlow model flavor gives you more initial head start. This is the core idea behind **Mlflow model** module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2a022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlflow_env]",
   "language": "python",
   "name": "conda-env-mlflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
