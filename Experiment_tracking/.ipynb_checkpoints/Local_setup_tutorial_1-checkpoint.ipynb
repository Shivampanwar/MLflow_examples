{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38ba767",
   "metadata": {},
   "source": [
    "MLflow concepts:\n",
    "\n",
    "MLflow runs can be recorded to local files, to a SQLAlchemy compatible database, or remotely to a tracking server. By default, the MLflow Python API logs runs locally to files in an mlruns directory wherever you ran your program. You can then run mlflow ui to see the logged runs.\n",
    "\n",
    "MLflow uses two components for storage: backend store and artifact store.\n",
    "While the **backend store** records runs, model's parameters, metrics, tags, notes, metadata, etc), the **artifact store** records artifacts like (files, models, images, in-memory objects, or model summary, etc).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301c092",
   "metadata": {},
   "source": [
    "### MLflow setup:\n",
    "\n",
    "Tracking server: no\n",
    "\n",
    "Backend store: local filesystem\n",
    "\n",
    "Artifacts store: local filesystem\n",
    "\n",
    "\n",
    "For this example both backend store and artifact store will be done locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e00416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76a0334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660b8d3",
   "metadata": {},
   "source": [
    "Till now, we don't have mlruns directory. It will be created after executing next cell in the present directory only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca90587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()\n",
    "## This will create the mlflow directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a330189e",
   "metadata": {},
   "source": [
    "**Creating an example and using new run**\n",
    "\n",
    "MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code. Each run records the following information:\n",
    "\n",
    "\n",
    "1. Code Version\n",
    "2. Git commit hash used for the run, if it was run from an MLflow Project.\n",
    "3. Start & End Time\n",
    "4. Parameters\n",
    "5. Key-value input parameters of your choice. Both keys and values are strings.\n",
    "6. Metrics\n",
    "7. Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9f0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6e08cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/13 16:18:10 INFO mlflow.tracking.fluent: Experiment with name 'my-experiment-1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1', experiment_id='1', lifecycle_stage='active', name='my-experiment-1', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"my-experiment-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44b5c5",
   "metadata": {},
   "source": [
    "We can log models in two ways. One using **mlflow.log_model** and one using **mlflow.log_artifacts**. We will see second flavor in a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e1c1f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1/bb83e25868804030af92cf41cafb57f7/artifacts'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    mlflow.set_tag(key = \"Message\",value=\"This uses mlflow.log_model flavor to log the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fe521",
   "metadata": {},
   "source": [
    "Till now for \"my-experiment-1\" we have one run and correpondingly one folder indise mlfruns/1/ folder. Let's now change 'C' to 0.5 and then see.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e81d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1/fbe993708ddb49f48ea894e9ea7201d2/artifacts'\n"
     ]
    }
   ],
   "source": [
    "## let's now change c to 0.5 and then record the experiment\n",
    "mlflow.set_experiment(\"my-experiment-1\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.5, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d994285",
   "metadata": {},
   "source": [
    "Go inside mlruns folder. Folder with name mlruns\\1\\ denote experiment. This has now two folder correspoinding to each run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a9b84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1', experiment_id='1', lifecycle_stage='active', name='my-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f084b5d",
   "metadata": {},
   "source": [
    "### Creating an another experiment from here onwards\n",
    "Changes : using a different \"C\" value\n",
    "This will create another folder inside \"mlruns\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4feae25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/13 16:28:08 INFO mlflow.tracking.fluent: Experiment with name 'my-experiment-2' does not exist. Creating a new experiment.\n",
      "/home/shivam/anaconda3/envs/mlflow_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/2/c999f40eb7324678a49936adf3e8d185/artifacts'\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"my-experiment-2\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.8, \"random_state\": 56}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235ee864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/1', experiment_id='1', lifecycle_stage='active', name='my-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>,\n",
       " <Experiment: artifact_location='file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/2', experiment_id='2', lifecycle_stage='active', name='my-experiment-2', tags={}>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34274f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atrifact uri is file:///home/shivam/MLflow_examples/Experiment_tracking/mlruns/2/360754677fef4610b3c0cea0f32271d3/artifacts\n"
     ]
    }
   ],
   "source": [
    "print (\"Atrifact uri is {}\".format(str(mlflow.get_artifact_uri())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c552c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlflow_env]",
   "language": "python",
   "name": "conda-env-mlflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
